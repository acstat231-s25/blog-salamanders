---
title: "Data Wrangling"
format: html
editor: visual
---

```{r}
#| label: set-up
#| include: false

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small",   # slightly smaller font for code
  message=FALSE)   

# load packages here
library(rvest)
library(tidyverse)
library(kableExtra)
library(mdsr)
library(stringr)
library(robotstxt)
library(tidytext)
library(lubridate)
```

```{r}
#| label: check permission & scrape songs

# check permissions ----------------------------------------------------------
songs_url <- "https://cs.uwaterloo.ca/~dtompkin/music/list/Best9.html"
paths_allowed(songs_url)
# scrape the table -----------------------------------------------------------
songs <- songs_url |>
  read_html() |>
  html_elements("table") |>
  purrr::pluck(2) |>
  html_table()  

```

```{r}
#| label: cleanup table

songs_clean <- songs |> 
  select(-X2,-X10) |>
  rename(number = X1, artist = X3, title = X4, time = X5
         , bpm = X6, year = X7 , genre = X8, track = X9) |>
  filter(artist != "ARTIST") |>
  mutate(track_gen = str_remove(track, "-..")
         , number = as.numeric(number)
         , time = ms(time)
         , bpm = as.numeric(bpm)
         , year = as.numeric(year) )
```

```{r}
#| label: create vectors & urls

# create vectors compatible with paste0
tracks <- as.vector(unlist(songs_clean['track']))
tracks_gens <- as.vector(unlist(songs_clean['track_gen']))
titles <- as.vector(unlist(songs_clean['title']))

# build urls
urls2 <- paste0("https://cs.uwaterloo.ca/~dtompkin/music/track/"
                , tracks_gens, "/", tracks, ".html")
head(urls2)
```

```{r}
#| label: scraping lyrics & adding to `songs_clean`

# Identify number of iterations (start with 1!)
n_iter <- 500
# Pre-allocate space
song_lyrics1 <- tibble(title = titles, url = urls2) |>
  # Limit to only the rows we are trying to work with
  slice(1:n_iter)

lyrics_df <- tibble(# Create empty character vector the same
  # length as our song titles vector
  lyrics = vector(mode = "character", length = length(titles))) |>
  slice(1:n_iter) 
# Iterate through links to grab lyrics
for (i in 1:n_iter) {
  if (i == 260) {
    next
  }
  
  lyrics_df$lyrics[i] <- song_lyrics1$url[i] |>
  read_html() |>
  html_elements("table") |>
  purrr::pluck(6) |>
  html_element(xpath = ".//tr[3]/td[1]") |>
  html_text2() |>
  str_replace_all("[\\n\\r]+", " ") |>  # Replace line breaks with a space
  str_squish()
  
}
# combine the two datafiles
song_lyrics1 <- bind_cols(song_lyrics1, lyrics_df)

# merge song_lyrics with songs_clean to add `url` and `lyrics` to songs_clean
merged_songs <- songs_clean |>
  left_join(song_lyrics1 |> select(title, url, lyrics), by = "title")

```

```{r}
#| label: Word Frequencies tab datasets

# combine all four Rock decades into one genre `Rock`
# & all Dance decades into one genre `Dance`
merged_songs_combined <- merged_songs |>
  filter(number <= 500) |>
  mutate(genre_combined = case_when(
    str_detect(genre, "Rock") ~ "Rock",
    str_detect(genre, "Dance") ~ "Dance",
    TRUE ~ genre
  )) |>
# create `decade` with just years for faceting
 mutate(decade = str_extract(genre, "\\d{4}s")) |>
  relocate(genre_combined, .after = genre) |>
  relocate(decade, .after = genre_combined) 

 
 # df for `Rock` word frequencies for word clouds
 Rock_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Rock") |>
   select(title, genre, decade, lyrics) |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, decade, sort = TRUE)
 
# df for `Dance` word frequencies for word clouds
 Dance_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Dance") |>
   select(title, genre, decade, lyrics) |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, decade, sort = TRUE)
 
# df for `Slow` word frequencies for word clouds
 Slow_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Slow") |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, sort = TRUE)
```

```{r}
#| label: Top Artists tab datasets

 # df for rankings 
songs_chart <- songs_clean |>
  mutate(
    block = case_when(
      # create var for general rank
      number > 400 & number < 501 ~ "500s"
      , number > 300 & number < 401 ~ "400s"
      , number > 200 & number < 301 ~ "300s"
      , number > 100 & number < 201 ~ "200s"
      , number < 101  ~ "Top 100"
      )
    , decade = case_when(
      # create var for decade
      year > 1949 & year < 1960 ~ "The 1950s"
      , year > 1959 & year < 1970 ~ "The 1960s"
      , year > 1969 & year < 1980 ~ "The 1970s"
      , year > 1979 & year < 1990 ~ "The 1980s"
      , year > 1989 & year < 2000 ~ "The 1990s"
      , year > 1999 & year < 2010 ~ "2000s"
      )
    )
# sort decades into logical order for legends
songs_chart$decade = 
   factor(songs_chart$decade
          , levels = c('The 1950s', 'The 1960s', 'The 1970s', "The 1980s"
                       , 'The 1990s', '2000s'))
# sort rank blocks into order that best demonstrates top 100 distribution
songs_chart$block =
  factor(songs_chart$block
         , levels = c('500s', '400s', '300s', '200s', 'Top 100'))
# df for top 3 artists
top_artists <- songs_chart |>
    filter(artist == "The Beatles" | artist == "The Rolling Stones"
           | artist == "Bob Dylan")
# sort decades into logical order for legends
top_artists$decade = 
   factor(top_artists$decade
          , levels = c('The 2000s', 'The 1990s', 'The 1980s', 'The 1970s'
                       , 'The 1960s', 'The 1950s')) 


```

```{r}
#| label: Sentiment Analysis tab datasets

afinn_lexicon = get_sentiments("afinn")

# create dataset with all matched words from song lyrics and AFINN lexicon
# with their respective sentiment scores
words_with_sentiment = merged_songs |>
  unnest_tokens(output = word, input = lyrics, token = "words") |>
  inner_join(afinn_lexicon, by = "word") |>
  mutate(year = as.numeric(year),
         # calculate total length (in seconds) of each song
         time_seconds = minute(time) * 60 + second(time),
         bpm = as.numeric(bpm))

# obtain average sentiment score, time, and bpm for lyrics of all songs in each year
sentiment_by_year <- words_with_sentiment |>
  group_by(year) |>
  summarize(
    average_sentiment = round(mean(value, na.rm = TRUE), 2),
    average_time_seconds = round(mean(time_seconds, na.rm = TRUE), 2),
    average_bpm = round(mean(bpm, na.rm = TRUE), 2),
    num_songs = n_distinct(title)) |>
  arrange(year)

# obtain average sentiment score, time, and bpm for lyrics of all songs in each genre
sentiment_by_genre <- words_with_sentiment |>
  group_by(genre) |>
  summarize(
    average_sentiment = round(mean(value, na.rm = TRUE), 2),
    average_time_seconds = round(mean(time_seconds, na.rm = TRUE), 2),
    average_bpm = round(mean(bpm, na.rm = TRUE), 2),
    num_songs = n_distinct(title)) |>
  arrange(genre)

sentiment_by_song <- words_with_sentiment |>
  group_by(title, artist, year, genre, time_seconds, bpm) |>
  summarize(average_sentiment = round(mean(value, na.rm = TRUE), 2)) |>
  mutate(genre_grouped = case_when(
    genre %in% c("Rock 1950s", "Rock 1960s",
                 "Rock 1970s", "Rock 1980s",
                 "Rock 1990s", "Rock 2000s") ~ "Rock",
    genre %in% c("Dance 1960s", "Dance 1970s",
                 "Dance 1980s") ~ "Dance",
    genre %in% c("R&B 1980s", "R&B 1990s") ~ "R&B",
    TRUE ~ genre)) |>
  arrange(title)
  
# calculate average sentiment by artist
sentiment_by_artist <- sentiment_by_song |> 
  filter(artist == "The Beatles" 
         | artist == "The Rolling Stones" 
         | artist == "Bob Dylan") |>
  group_by(artist) |>
  summarize(mean = mean(average_sentiment)) |>
  mutate(mean = signif(mean, digits = 2))

```

```{r}
#| label: creating csv files

# merged_songs
write_csv(merged_songs, "data/merged_songs.csv")

# merged_songs_combined
write_csv(merged_songs_combined, "data/merged_songs_combined.csv")

# Rock_lyrics_word_freqs
write_csv(Rock_lyrics_word_freqs, "data/Rock_lyrics_word_freqs.csv")

# Dance_lyrics_word_freqs
write_csv(Dance_lyrics_word_freqs, "data/Dance_lyrics_word_freqs.csv")

# Slow_lyrics_word_freqs
write_csv(Slow_lyrics_word_freqs, "data/Slow_lyrics_word_freqs.csv")

# sentiment_by_year
write_csv(sentiment_by_year, "data/sentiment_by_year.csv")

# sentiment_by_genre
write_csv(sentiment_by_genre, "data/sentiment_by_genre.csv")

# sentiment_by_song
write_csv(sentiment_by_song, "data/sentiment_by_song.csv")

# top artists
write_csv(top_artists, "data/top_artists.csv")

# top artist average sentiment
write_csv(sentiment_by_artist, "data/sentiment_by_artists.csv")

# rankings
write_csv(songs_chart, "data/songs_chart.csv")

```


