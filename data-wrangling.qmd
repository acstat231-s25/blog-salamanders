---
title: "Data Wrangling"
format: html
editor: visual
---

```{r}
#| label: set-up
#| include: false

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small",   # slightly smaller font for code
  message=FALSE)   

# load packages here
library(rvest)
library(tidyverse)
library(kableExtra)
library(mdsr)
library(stringr)
library(robotstxt)
library(tidytext)
library(dplyr)
library(lubridate)
library(scales)
```

```{r}
# check permissions ----------------------------------------------------------
songs_url <- "https://cs.uwaterloo.ca/~dtompkin/music/list/Best9.html"
paths_allowed(songs_url)
# scrape the table -----------------------------------------------------------
songs <- songs_url |>
  read_html() |>
  html_elements("table") |>
  purrr::pluck(2) |>
  html_table()  

```

```{r}
#| label: cleanup table


songs_clean <- songs |> 
  select(-X2,-X10) |>
  rename(number = X1, artist = X3, title = X4, time = X5
         , bpm = X6, year = X7 , genre = X8, track = X9) |>
  filter(artist != "ARTIST") |>
  mutate(track_gen = str_remove(track, "-..")
         , number = as.numeric(number)
         , time = ms(time)
         , bpm = as.numeric(bpm)
         , year = as.numeric(year) )
```

```{r}
# create vectors compatible with paste0
tracks <- as.vector(unlist(songs_clean['track']))
tracks_gens <- as.vector(unlist(songs_clean['track_gen']))
titles <- as.vector(unlist(songs_clean['title']))

# build urls
urls2 <- paste0("https://cs.uwaterloo.ca/~dtompkin/music/track/"
                , tracks_gens, "/", tracks, ".html")
head(urls2)
```

```{r}

# Identify number of iterations (start with 1!)
n_iter <- 500
# Pre-allocate space
song_lyrics1 <- tibble(title = titles, url = urls2) |>
  # Limit to only the rows we are trying to work with
  slice(1:n_iter)

lyrics_df <- tibble(# Create empty character vector the same
  # length as our titles vector
  lyrics = vector(mode = "character", length = length(titles))) |>
  slice(1:n_iter) 
# Iterate through links to grab nursery rhyme text
for (i in 1:n_iter) {
  # Scrape song i's lyric table and save it to row i of the `text` variable
  #tables <- song_lyrics1$url[i] |>
  #  read_html() |>
  #  html_elements("table") |>
  #  purrr::pluck(6) |>
  #  html_table()
  # extract cell of table with lyrics
  #lyrics_df$lyrics[i] <- tables[[3, 1]] |>
  #  str_replace_all("[\r\n]+", " ")
  
  if (i == 260) {
    next
  }
  
  lyrics_df$lyrics[i] <- song_lyrics1$url[i] |>
  read_html() |>
  html_elements("table") |>
  purrr::pluck(6) |>
  html_element(xpath = ".//tr[3]/td[1]") |>
  html_text2() |>
  str_replace_all("[\\n\\r]+", " ") |>  # Replace line breaks with a space
  str_squish()
  
}
# combine the two datafiles
song_lyrics1 <- bind_cols(song_lyrics1, lyrics_df)

# merge song_lyrics with songs_clean to add `url` and `lyrics` to songs_clean
merged_songs <- songs_clean |>
  left_join(song_lyrics1 |> select(title, url, lyrics), by = "title")

```

```{r}
#| label: creating additional, necessary datasets

# combine all four Rock decades into one genre `Rock`
# & all Dance decades into one genre `Dance`
merged_songs_combined <- merged_songs |>
  filter(number <= 500) |>
  mutate(genre_combined = case_when(
    str_detect(genre, "Rock") ~ "Rock",
    str_detect(genre, "Dance") ~ "Dance",
    TRUE ~ genre
  )) |>
  # create `decade` with just years for faceting
 mutate(decade = str_extract(genre, "\\d{4}s")) |>
  relocate(genre_combined, .after = genre) |>
  relocate(decade, .after = genre_combined) 

# create bigrams dataset for lyrics (might not need)
 merged_songs_bigrams <- merged_songs |>
  filter(number <= 250) |>
    unnest_tokens(output = bigram, input = lyrics, token = "ngrams", n = 2) |>
   select(number, artist, title, bigram)
 
 # create trigrams dataset for lyrics (might not need)
 merged_songs_trigrams <- merged_songs |>
  filter(number <= 250) |>
   unnest_tokens(output = trigram, input = lyrics, token = "ngrams", n = 3) |>
   select(number, artist, title, trigram)
 
 # df for `Rock` word frequencies for word clouds
 Rock_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Rock") |>
   select(title, genre, decade, lyrics) |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, decade, sort = TRUE)
 
# df for `Dance` word frequencies for word clouds
 Dance_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Dance") |>
   select(title, genre, decade, lyrics) |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, decade, sort = TRUE)
 
# df for `Slow` word frequencies for word clouds
 Slow_lyrics_word_freqs <- merged_songs_combined |>
  filter(number <= 250) |>
   filter(genre_combined == "Slow") |>
    unnest_tokens(output = word, input = lyrics) |>
    anti_join(stop_words, by = "word") |>
    count(word, sort = TRUE)
 
 # df for rankings 
songs_chart <- songs_clean |>
  mutate(
    block = case_when(
      # create var for general rank
      number > 400 & number < 501 ~ "500s"
      , number > 300 & number < 401 ~ "400s"
      , number > 200 & number < 301 ~ "300s"
      , number > 100 & number < 201 ~ "200s"
      , number < 101  ~ "Top 100"
      )
    , decade = case_when(
      # create var for decade
      year > 1949 & year < 1960 ~ "50s"
      , year > 1959 & year < 1970 ~ "60s"
      , year > 1969 & year < 1980 ~ "70s"
      , year > 1979 & year < 1990 ~ "80s"
      , year > 1989 & year < 2000 ~ "90s"
      , year > 1999 & year < 2010 ~ "2000s"
      )
    )
# sort decades into logical order for legends
songs_chart$decade = 
   factor(songs_chart$decade
          , levels = c('50s', '60s', '70s', "80s", '90s', '2000s'))
# sort rank blocks into order that best demonstrates top 100 distribution
songs_chart$block =
  factor(songs_chart$block
         , levels = c('500s', '400s', '300s', '200s', 'Top 100'))
# df for top 3 artists
top_artists <- songs_chart |>
    filter(artist == "The Beatles" | artist == "The Rolling Stones"
           | artist == "Bob Dylan")
# sort decades into logical order for legends
top_artists$decade = 
   factor(top_artists$decade
          , levels = c('2000s', '90s', '80s', '70s', '60s', '50s'))  

```

```{r}

afinn_lexicon = get_sentiments("afinn")

# create dataset with all matched words from song lyrics and AFINN lexicon
# with their respective sentiment scores
words_with_sentiment = merged_songs |>
  unnest_tokens(output = word, input = lyrics, token = "words") |>
  inner_join(afinn_lexicon, by = "word") |>
  mutate(year = as.numeric(year),
         # calculate total length (in seconds) of each song
         time_seconds = minute(time) * 60 + second(time),
         bpm = as.numeric(bpm))

# obtain average sentiment score, time, and bpm for lyrics of all songs in each year
sentiment_by_year <- words_with_sentiment |>
  group_by(year) |>
  summarize(
    average_sentiment = round(mean(value, na.rm = TRUE), 2),
    average_time_seconds = round(mean(time_seconds, na.rm = TRUE), 2),
    average_bpm = round(mean(bpm, na.rm = TRUE), 2),
    num_songs = n_distinct(title)) |>
  arrange(year)

# obtain average sentiment score, time, and bpm for lyrics of all songs in each genre
sentiment_by_genre <- words_with_sentiment |>
  group_by(genre) |>
  summarize(
    average_sentiment = round(mean(value, na.rm = TRUE), 2),
    average_time_seconds = round(mean(time_seconds, na.rm = TRUE), 2),
    average_bpm = round(mean(bpm, na.rm = TRUE), 2),
    num_songs = n_distinct(title)) |>
  arrange(genre)

sentiment_by_song <- words_with_sentiment |>
  group_by(title, artist, year, genre, time_seconds, bpm) |>
  summarize(average_sentiment = round(mean(value, na.rm = TRUE), 2)) |>
  mutate(genre_grouped = case_when(genre %in% c("Rock 1950s", "Rock 1960s",
                                                "Rock 1970s", "Rock 1980s",
                                                "Rock 1990s", "Rock 2000s") ~ "Rock",
                                   genre %in% c("Dance 1960s", "Dance 1970s",
                                                "Dance 1980s") ~ "Dance",
                                   genre %in% c("R&B 1980s", "R&B 1990s") ~ "R&B",
                                   TRUE ~ genre)) |>
  arrange(title)
  

```

```{r}
#| label: creating csv files

# merged_songs
write_csv(merged_songs, "data/merged_songs.csv")
read_csv("data/merged_songs.csv")

# merged_songs_combined
write_csv(merged_songs_combined, "data/merged_songs_combined.csv")
read_csv("data/merged_songs_combined.csv")

# merged_songs_bigrams
write_csv(merged_songs_bigrams, "data/merged_songs_bigrams.csv")
read_csv("data/merged_songs_bigrams.csv")

# merged_songs_trigrams
write_csv(merged_songs_trigrams, "data/merged_songs_trigrams.csv")
read_csv("data/merged_songs_trigrams.csv")

# lyrics_word_freqs
#write_csv(lyrics_word_freqs, "data/lyrics_word_freqs.csv")
#read_csv("data/lyrics_word_freqs.csv")

# sentiment_by_year
write_csv(sentiment_by_year, "data/sentiment_by_year.csv")
read_csv("data/sentiment_by_year.csv")

# sentiment_by_genre
write_csv(sentiment_by_genre, "data/sentiment_by_genre.csv")
read_csv("data/sentiment_by_genre.csv")

# sentiment_by_song
write_csv(sentiment_by_song, "data/sentiment_by_song.csv")
read_csv("data/sentiment_by_song.csv")

# write and read csv for word freqs datasets

```

```{r}
# jenna visualization workspace

library(ggwordcloud)
library(xfun)
library(RColorBrewer)
library(wordcloud)
library(ggpubr)

# Rock cumulative word cloud
Rock_lyrics_word_freqs |>
    with(wordcloud(words = word,
                   freq = n,
                  # min.freq = 20,
                  max.words = 50,
# Plot the words in a random order
random.order = TRUE,
# Specify the range of the size of the words
scale = c(3, 0.3),
# Specify proportion of words with 90 degree rotation
rot.per = 0.15,
# Color words from least to most frequent
colors = brewer.pal(10, "Dark2"),
# Change font family
family = "sans"))

# 1970s Rock decade
Rock1 <- ggplot(Rock_lyrics_word_freqs |> filter(decade == "1970s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",             
    random.order = TRUE,           
    max.words = 25, 
    # Size scale for words
    scale = c(2, 0.3),    
    # Percentage of words rotated
    rotate_ratio = 0.15,          
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE           
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) + 
  ggtitle("Rock Word Cloud - 1970s") +  
  theme_minimal() +  
  theme(legend.position = "none",  
        plot.background = element_rect(fill = "white", color = "white")) 

# 1980s Rock decade
Rock2 <- ggplot(Rock_lyrics_word_freqs |> filter(decade == "1980s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",             
    random.order = TRUE,           
    max.words = 25,    
    # Size scale for words
    scale = c(2, 0.3),    
    # Percentage of words rotated
    rotate_ratio = 0.15,           
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE         
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) + 
  ggtitle("Rock Word Cloud - 1980s") +  
  theme_minimal() +  
  theme(legend.position = "none",  
        plot.background = element_rect(fill = "white", color = "white"))

# 1990s Rock decade
Rock3 <- ggplot(Rock_lyrics_word_freqs |> filter(decade == "1990s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",               
    random.order = TRUE,           
    max.words = 25,  
    # Size scale for words
    scale = c(2, 0.3),
    # Percentage of words rotated
    rotate_ratio = 0.15, 
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE             
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) +  
  ggtitle("Rock Word Cloud - 1990s") +  
  theme_minimal() + 
  theme(legend.position = "none", 
        plot.background = element_rect(fill = "white", color = "white"))

# 2000s Rock decade
Rock4 <- ggplot(Rock_lyrics_word_freqs |> filter(decade == "2000s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",           
    random.order = TRUE,         
    max.words = 25,   
    # Size scale for words
    scale = c(2, 0.3),     
    # Percentage of words rotated
    rotate_ratio = 0.15,           
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE 
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) + 
  ggtitle("Rock Word Cloud - 2000s") +
  theme_minimal() + 
  theme(legend.position = "none", 
        plot.background = element_rect(fill = "white", color = "white"))

#arrange four clouds for one tab
ggarrange(Rock1, Rock2, Rock3, Rock4, ncol = 2, nrow = 2)
```

```{r}
# jenna visualization workspace

# if max.words is removed, use this df
Dance_top_words <- Dance_lyrics_word_freqs |>
  slice_max(n, n = 50)

# Dance cumulative word cloud
Dance_lyrics_word_freqs |>
    with(wordcloud(words = word,
                   freq = n,
                  # min.freq = 20,
                  max.words = 50,
# Plot the words in a random order
random.order = TRUE,
# Specify the range of the size of the words
scale = c(3, 0.3),
# Specify proportion of words with 90 degree rotation
rot.per = 0.15,
# Color words from least to most frequent
colors = brewer.pal(10, "Dark2"),
# Change font family
family = "sans"))

# 1960s Dance decade
Dance1 <- ggplot(Dance_lyrics_word_freqs |> filter(decade == "1960s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",             
    random.order = TRUE,           
    max.words = 25, 
    # Size scale for words
    scale = c(2, 0.3),    
    # Percentage of words rotated
    rotate_ratio = 0.15,          
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE          
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) + 
  ggtitle("Dance Word Cloud - 1960s") +  
  theme_minimal() +  
  theme(legend.position = "none",  
        plot.background = element_rect(fill = "white", color = "white")) 

# 1970s Dance decade
Dance2 <- ggplot(Dance_lyrics_word_freqs |> filter(decade == "1970s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",             
    random.order = TRUE,           
    max.words = 25,    
    # Size scale for words
    scale = c(2, 0.3),    
    # Percentage of words rotated
    rotate_ratio = 0.15,           
    # Use `color` for word color, depending on frequency
    show.legend = FALSE ,
    rm_outside = TRUE           
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) + 
  ggtitle("Dance Word Cloud - 1970s") +  
  theme_minimal() +  
  theme(legend.position = "none",  
        plot.background = element_rect(fill = "white", color = "white"))

# 1980s Dance decade
Dance3 <- ggplot(Dance_lyrics_word_freqs |> filter(decade == "1980s"), 
                aes(label = word, size = n, color = n)) +  
  geom_text_wordcloud(
    family = "sans",               
    random.order = TRUE,           
    max.words = 25,  
    # Size scale for words
    scale = c(2, 0.3),
    # Percentage of words rotated
    rotate_ratio = 0.15, 
    # Use `color` for word color, depending on frequency
    show.legend = FALSE,
    rm_outside = TRUE             
  ) +
  scale_color_gradientn(colors = brewer.pal(9, "Set1")) +  
  ggtitle("Dance Word Cloud - 1980s") +  
  theme_minimal() + 
  theme(legend.position = "none", 
        plot.background = element_rect(fill = "white", color = "white"))

#arrange four clouds for one tab
ggarrange(Dance1, Dance2, Dance3, ncol = 2, nrow = 2)


```

```{r}
# jenna visualization workspace

# Slow word cloud
Slow_lyrics_word_freqs |>
    with(wordcloud(words = word,
                   freq = n,
                  # min.freq = 20,
                  max.words = 50,
random.order = TRUE,
# Specify the range of the size of the words
scale = c(3, 0.3),
# Specify proportion of words with 90 degree rotation
rot.per = 0.15,
# Color words from least to most frequent
colors = brewer.pal(10, "Dark2"),
family = "sans"))

```



```{r}
# Claire visualization workspace
library(RColorBrewer)
# bpm vis
songs_chart |> 
  # Create segmented histogram
  ggplot(aes(x = bpm, fill = decade)) +
    geom_histogram(position = "stack", color = "black") +
    labs(
     title = "BPM in the Rolling Stone Top 500"
     , subtitle = "Broken Down By Rank"
     , x = "Beats per minute (bpm)"
     , y = "Count"
     , tag = " "
     , caption = " "
     ) +
    scale_fill_discrete(name = "Rank") +
    theme_linedraw() +
    theme(legend.text = element_text(size = rel(0.75))) +
    theme(title = element_text(size = rel(0.75))) +
    theme(plot.caption = element_text(hjust = -0.5))  +
    theme(axis.title.x = element_text(size = rel(1.5))) +
    theme(axis.text.x = element_text(size = rel(1.25)))


# duration vis
songs_chart |> 
  # Create segmented histogram
  ggplot(aes(x = time, fill = decade)) +
    geom_histogram(position = "stack", color = "black") +
    labs(
     title = "Song Durations of the Rolling Stone Top 500"
     , subtitle = "Broken Down by Rank"
     , x = "Song duration"
     , y = "Count"
     , tag = " "
     , caption = " "
     ) +
    scale_fill_discrete(name = "Rank") +
    theme_linedraw() +
    theme(legend.text = element_text(size = rel(0.75))) +
    theme(title = element_text(size = rel(0.75))) +
    theme(plot.caption = element_text(hjust = -0.5))  +
    theme(axis.title.x = element_text(size = rel(1.5))) +
    theme(axis.text.x = element_text(size = rel(1.25)))

# decade vis
songs_chart |> 
  # Create segmented histogram
  ggplot(aes(x = decade, fill = block)) +
    geom_bar(position = "stack", color = "black") +
    labs(
     title = "Decades in the Rolling Stone Top 500"
     , subtitle = "Broken Down By Rank"
     , x = "Decade of Release"
     , y = "Count"
     , tag = " "
     , caption = " "
     ) +
    scale_fill_discrete(name = "Rank") +
    theme_linedraw() +
    theme(legend.text = element_text(size = rel(0.75))) +
    theme(title = element_text(size = rel(0.75))) +
    theme(plot.caption = element_text(hjust = -0.5)) +
    theme(axis.title.x = element_text(size = rel(1.5))) +
    theme(axis.text.x = element_text(size = rel(1.25)))


top_artists |> 
  # Create segmented histogram
  ggplot(aes(x = artist, fill = decade)) +
    geom_bar(position = "stack") +
    
    labs(
     title = "The Top 3 Most Represented Artists in the Rolling Stone Top 500"
     , subtitle = "Broken Down by the Decade Their Songs Were Released"
     , x = "Artist"
     , y = "Count"
     , tag = " "
     , caption = " "
     ) +
    scale_fill_discrete(name = "Decade") +
    theme_linedraw() +
    coord_flip() +
    theme(legend.text = element_text(size = rel(0.75))) +
    theme(title = element_text(size = rel(0.75))) +
    theme(axis.title.x = element_text(size = rel(1.25))) +
    theme(axis.title.y = element_blank()
          , axis.text.y = element_blank()
          , axis.ticks.y = element_blank())

prop.table(table(songs_chart$decade))

ggplot(songs_chart, aes(x = decade, y = number)) +
  geom_boxplot() +
  scale_y_reverse()



# Plot
plot <- ggplot(df, aes(x=stack, y=val, fill=cat)) +
  geom_bar(stat="identity", position="stack") +
  geom_text(aes(y=pos, label=labels), vjust=0)
plot
```
